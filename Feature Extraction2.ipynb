{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import spkit as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import mne\n",
    "from copy import deepcopy\n",
    "from mne.preprocessing import compute_proj_ecg\n",
    "from mne_connectivity import envelope_correlation\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from mne.preprocessing import ICA, corrmap, create_ecg_epochs, create_eog_epochs\n",
    "from mne.preprocessing import annotate_amplitude\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from scipy.signal import welch, coherence\n",
    "from scipy.stats import entropy, skew, kurtosis\n",
    "import networkx as nx\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "#import tsfresh\n",
    "#from tsfresh import extract_features\n",
    "#from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "#from pyrqa.time_series import TimeSeries\n",
    "from pyrqa.settings import Settings\n",
    "from pyrqa.analysis_type import Classic\n",
    "from pyrqa.neighbourhood import FixedRadius\n",
    "from pyrqa.metric import EuclideanMetric\n",
    "from pyrqa.computation import RQAComputation\n",
    "import pyrqa\n",
    "import mne\n",
    "from mne.decoding import CSP\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pywt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torchvision.models import mobilenet_v2\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from ordpy import renyi_entropy\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('mne').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPG_Dataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.filepaths, self.labels = self._load_filepaths_and_labels()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepaths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filepath = self.filepaths[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        eeg_data = self._load_eeg(filepath)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            eeg_data = self.transform(eeg_data)\n",
    "\n",
    "        return torch.tensor(eeg_data), torch.tensor(label)\n",
    "\n",
    "    def _load_filepaths_and_labels(self):\n",
    "        filepaths = []\n",
    "        labels = []\n",
    "\n",
    "        classes = sorted(os.listdir(self.root_dir))\n",
    "        for class_index, class_name in enumerate(classes):\n",
    "            class_dir = os.path.join(self.root_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                filenames = os.listdir(class_dir)\n",
    "                for filename in filenames:\n",
    "                    filepaths.append(os.path.join(class_dir, filename))\n",
    "                    labels.append(class_index)\n",
    "\n",
    "        return filepaths, labels\n",
    "\n",
    "    def _load_eeg(self, filepath):\n",
    "        data = mne.read_epochs(filepath, preload=False).get_data(picks='eeg');\n",
    "        normals = []\n",
    "        scaler = StandardScaler()\n",
    "        for idx in range(len(data)):\n",
    "            normals.append(scaler.fit_transform(data[idx]))\n",
    "\n",
    "        return np.array(normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    # Concatenate data samples along the first dimension (window_count)\n",
    "    # Assumes each sample is a tuple (uid, data_sample)\n",
    "    uids, data_samples = zip(*batch)\n",
    "    concatenated_data = torch.stack(data_samples, dim=0)\n",
    "    return uids, concatenated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLV(sample, verbose=False):\n",
    "        \n",
    "        EEG_data = sample[0]\n",
    "        threshold = 0.3\n",
    "        G = nx.Graph()\n",
    "\n",
    "        # Add nodes (brain regions)\n",
    "        G.add_nodes_from(range(21))  # Assuming 21 brain regions\n",
    "\n",
    "        # Add edges (based on functional connectivity)\n",
    "        for i in range(21):\n",
    "            for j in range(i + 1, 21):\n",
    "                # Calculate functional connectivity strength between nodes i and j\n",
    "                # (e.g., using correlation coefficients from EEG signals)\n",
    "\n",
    "                #phase locking value\n",
    "                connectivity_strength = np.abs(np.mean(np.exp(1j * np.angle(EEG_data[i] * np.conj(EEG_data[j])))))  # Replace with actual method\n",
    "\n",
    "                if connectivity_strength > threshold:\n",
    "                    G.add_edge(i, j, weight=connectivity_strength)\n",
    "\n",
    "        # Calculate graph metrics\n",
    "        local_efficiency = nx.local_efficiency(G)\n",
    "        global_efficiency = nx.global_efficiency(G)\n",
    "\n",
    "        if (verbose):\n",
    "                \n",
    "            print(f\"Local efficiency: {local_efficiency}\")\n",
    "            print(f\"Global efficiency: {global_efficiency}\")\n",
    "\n",
    "        return local_efficiency, global_efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RQA(data_points, dimension):\n",
    "    time_series = TimeSeries(data_points,\n",
    "                         embedding_dimension = int(dimension),\n",
    "                         time_delay =2)\n",
    "    settings = Settings(time_series,\n",
    "                    analysis_type=Classic,\n",
    "                    neighbourhood=FixedRadius(0.1),\n",
    "                    similarity_measure=EuclideanMetric,\n",
    "                    theiler_corrector=1)\n",
    "    computation = RQAComputation.create(settings,\n",
    "                                    verbose=False)\n",
    "    result = computation.run()\n",
    "    rqa_features = [\n",
    "        result.recurrence_rate,\n",
    "        result.determinism,\n",
    "        result.divergence,\n",
    "        result.entropy_diagonal_lines,\n",
    "        result.laminarity,\n",
    "        result.trapping_time,\n",
    "        result.entropy_vertical_lines,\n",
    "        result.entropy_white_vertical_lines,\n",
    "    ]\n",
    "    \n",
    "    return np.array(rqa_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wavelet_features(signal, wavelet_name, level):\n",
    "    coeffs = pywt.wavedec(signal, wavelet_name, level=level)\n",
    "    features = []\n",
    "    for coeff in coeffs:\n",
    "        features.extend([np.mean(coeff), np.std(coeff)])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy(signal):\n",
    "    # Compute probability distribution\n",
    "    unique_values, counts = np.unique(signal, return_counts=True)\n",
    "    probabilities = counts / len(signal)\n",
    "\n",
    "    # Calculate Shannon entropy\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PLV(eeg_data):\n",
    "    PLVs = []\n",
    "    for channel in range(eeg_data.shape[0]):\n",
    "        if(channel!=20):\n",
    "            #print(channel)\n",
    "            plv = np.abs(np.mean(np.exp(1j * np.angle(eeg_data[channel] * np.conj(eeg_data[channel + 1])))))\n",
    "            PLVs.append(plv)\n",
    "        \n",
    "    PLVs.append(np.abs(np.mean(np.exp(1j * np.angle(eeg_data[20] * np.conj(eeg_data[0]))))))\n",
    "    return np.array(PLVs).reshape(21, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherence_features(eeg_data):\n",
    "    vals = []\n",
    "    for channel in range(eeg_data.shape[0]):\n",
    "        if(channel!=20):\n",
    "            #print(channel)\n",
    "            f, Cxy = coherence(eeg_data[channel], eeg_data[channel + 1], fs=300, nperseg=300)\n",
    "            vals.append(np.mean(Cxy))\n",
    "        \n",
    "    f, Cxy = coherence(eeg_data[20], eeg_data[0], fs=300, nperseg=300)\n",
    "    vals.append(np.mean(Cxy))\n",
    "    return np.array(vals).reshape(21, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eeg_features(eeg_data, wavelet_type = 'db4', wavelet_level = 4, include_rqa = False):\n",
    "    eeg_data = np.array(eeg_data)\n",
    "    num_channels = eeg_data.shape[0]\n",
    "\n",
    "    # Initialize arrays to store features\n",
    "    mean_values = np.zeros(num_channels)\n",
    "    std_values = np.zeros(num_channels)\n",
    "    min_values = np.zeros(num_channels)\n",
    "    max_values = np.zeros(num_channels)\n",
    "    skewness_values = np.zeros(num_channels)\n",
    "    kurtosis_values = np.zeros(num_channels)\n",
    "    p2p_values = np.zeros(num_channels)\n",
    "    p2rms_values = np.zeros(num_channels)\n",
    "    rss_values = np.zeros(num_channels)\n",
    "    amplitude = np.zeros(num_channels)\n",
    "    rms = np.zeros(num_channels)\n",
    "    zero_crossing_rate = np.zeros(num_channels)\n",
    "    delta_power = np.zeros(num_channels)\n",
    "    theta_power = np.zeros(num_channels)\n",
    "    alpha_power = np.zeros(num_channels)\n",
    "    beta_power = np.zeros(num_channels)\n",
    "    gamma_power = np.zeros(num_channels)\n",
    "    spectral_entropy = np.zeros(num_channels)\n",
    "    shannon_ent = np.zeros(num_channels)\n",
    "    renyi_ent = np.zeros(num_channels)\n",
    "    rqa_matrix = []\n",
    "\n",
    "    db_wavelet_features = []\n",
    "    for channel in eeg_data:\n",
    "        channel_features = extract_wavelet_features(channel, 'sym5', 4)\n",
    "        db_wavelet_features.append(channel_features)\n",
    "\n",
    "    sym_wavelet_features = []\n",
    "    for channel in eeg_data:\n",
    "        channel_features = extract_wavelet_features(channel, 'db4', 4)\n",
    "        sym_wavelet_features.append(channel_features)\n",
    "\n",
    "\n",
    "\n",
    "    for channel in range(num_channels):\n",
    "        # Extract data for the current channel\n",
    "        channel_data = eeg_data[channel]\n",
    "\n",
    "        # Compute mean, STD, min, max\n",
    "        mean_values[channel] = np.mean(channel_data)\n",
    "        std_values[channel] = np.std(channel_data)\n",
    "        min_values[channel] = np.min(channel_data)\n",
    "        max_values[channel] = np.max(channel_data)\n",
    "\n",
    "        # Compute skewness and kurtosis\n",
    "        skewness_values[channel] = skew(channel_data)\n",
    "        kurtosis_values[channel] = kurtosis(channel_data)\n",
    "\n",
    "        # Compute peak-to-peak (P2P)\n",
    "        p2p_values[channel] = max_values[channel] - min_values[channel]\n",
    "\n",
    "        # Compute peak-to-root sum square (P2RMS)\n",
    "        p2rms_values[channel] = np.sqrt(np.sum(channel_data**2))\n",
    "\n",
    "        # Compute root sum square (RSS)\n",
    "        rss_values[channel] = np.sqrt(np.sum(channel_data**2))\n",
    "\n",
    "        # Compute amplitude (peak-to-peak divided by 2)\n",
    "        amplitude[channel] = p2p_values[channel] / 2\n",
    "\n",
    "        # Compute root mean square (RMS)\n",
    "        rms[channel] = np.sqrt(np.mean(channel_data**2))\n",
    "\n",
    "        # Compute zero-crossing rate\n",
    "        zero_crossing_rate[channel] = np.mean(np.diff(np.sign(channel_data)) != 0)\n",
    "\n",
    "        # Compute power spectral density using Welch method\n",
    "        f, psd = welch(channel_data, fs=1000, nperseg=256)\n",
    "        delta_power[channel] = np.sum(psd[(f >= 1) & (f <= 4)])\n",
    "        theta_power[channel] = np.sum(psd[(f >= 4) & (f <= 8)])\n",
    "        alpha_power[channel] = np.sum(psd[(f >= 8) & (f <= 14)])\n",
    "        beta_power[channel] = np.sum(psd[(f >= 14) & (f <= 30)])\n",
    "        gamma_power[channel] = np.sum(psd[f > 30])\n",
    "        if(include_rqa):\n",
    "            rqa_matrix.append(RQA(channel_data, dimension=4))\n",
    "\n",
    "        # Compute spectral entropy\n",
    "        spectral_entropy[channel] = -np.sum(psd * np.log2(psd))\n",
    "        #shannon_ent[channel] = shannon_entropy(channel_data)\n",
    "        #renyi_ent[channel] = renyi_entropy(channel_data, 3)\n",
    "\n",
    "\n",
    "    # Organize features into a dictionary\n",
    "    features = np.array([mean_values, std_values, min_values, max_values, skewness_values, kurtosis_values,\n",
    "                         p2p_values, p2rms_values, rss_values,amplitude, rms, zero_crossing_rate,delta_power,\n",
    "                         theta_power, alpha_power, beta_power, gamma_power]).T\n",
    "    if(include_rqa):\n",
    "        features = np.append(features, np.array(rqa_matrix), axis=1)\n",
    "\n",
    "    features = np.append(features, db_wavelet_features, axis=1)\n",
    "    #features = np.append(features, sym_wavelet_features, axis=1)\n",
    "\n",
    "    #features = np.append(features, PLV(eeg_data), axis = 1)\n",
    "    #features = np.append(features, coherence_features(eeg_data), axis= 1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "#extracted_features = extract_eeg_features(sample[0])\n",
    "#extracted_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Data(path, wavelet_type, wavelet_level, include_rqa, verbose):\n",
    "    dataset = FPG_Dataset(root_dir=path)\n",
    "\n",
    "    batch_size = 1  # Set your desired batch size\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "    label = []\n",
    "    feature_space = []\n",
    "    count = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        for patient in inputs:\n",
    "            \n",
    "            for epoch in patient:\n",
    "                feature_space.append(extract_eeg_features(epoch, wavelet_type, wavelet_level, include_rqa))\n",
    "                label.append(targets)\n",
    "            \n",
    "            if(verbose):\n",
    "                print(\"Patient processed\")\n",
    "                print(count)\n",
    "                count = count + 1\n",
    "    \n",
    "    feature_space = np.squeeze(feature_space)\n",
    "    labels = np.array([tensor.numpy() for tensor in label])\n",
    "    flat_features = feature_space.reshape(feature_space.shape[0], -1)\n",
    "\n",
    " \n",
    "    return feature_space, labels.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = FPG_Dataset(root_dir=r\"C:\\Users\\mhfar\\OneDrive\\Desktop\\20second_MNE_3CLASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient processed\n",
      "0\n",
      "Patient processed\n",
      "1\n",
      "Patient processed\n",
      "2\n",
      "Patient processed\n",
      "3\n",
      "Patient processed\n",
      "4\n",
      "Patient processed\n",
      "5\n",
      "Patient processed\n",
      "6\n",
      "Patient processed\n",
      "7\n",
      "Patient processed\n",
      "8\n",
      "Patient processed\n",
      "9\n",
      "Patient processed\n",
      "10\n",
      "Patient processed\n",
      "11\n",
      "Patient processed\n",
      "12\n",
      "Patient processed\n",
      "13\n",
      "Patient processed\n",
      "14\n",
      "Patient processed\n",
      "15\n",
      "Patient processed\n",
      "16\n",
      "Patient processed\n",
      "17\n",
      "Patient processed\n",
      "18\n",
      "Patient processed\n",
      "19\n",
      "Patient processed\n",
      "20\n",
      "Patient processed\n",
      "21\n",
      "Patient processed\n",
      "22\n",
      "Patient processed\n",
      "23\n",
      "Patient processed\n",
      "24\n",
      "Patient processed\n",
      "25\n",
      "Patient processed\n",
      "26\n",
      "Patient processed\n",
      "27\n",
      "Patient processed\n",
      "28\n",
      "Patient processed\n",
      "29\n",
      "Patient processed\n",
      "30\n",
      "Patient processed\n",
      "31\n",
      "Patient processed\n",
      "32\n",
      "Patient processed\n",
      "33\n",
      "Patient processed\n",
      "34\n",
      "Patient processed\n",
      "35\n",
      "Patient processed\n",
      "36\n",
      "Patient processed\n",
      "37\n",
      "Patient processed\n",
      "38\n",
      "Patient processed\n",
      "39\n",
      "Patient processed\n",
      "40\n",
      "Patient processed\n",
      "41\n",
      "Patient processed\n",
      "42\n",
      "Patient processed\n",
      "43\n",
      "Patient processed\n",
      "44\n",
      "Patient processed\n",
      "45\n",
      "Patient processed\n",
      "46\n",
      "Patient processed\n",
      "47\n",
      "Patient processed\n",
      "48\n",
      "Patient processed\n",
      "49\n",
      "Patient processed\n",
      "50\n",
      "Patient processed\n",
      "51\n",
      "Patient processed\n",
      "52\n",
      "Patient processed\n",
      "53\n",
      "Patient processed\n",
      "54\n",
      "Patient processed\n",
      "55\n",
      "Patient processed\n",
      "56\n",
      "Patient processed\n",
      "57\n",
      "Patient processed\n",
      "58\n",
      "Patient processed\n",
      "59\n",
      "Patient processed\n",
      "60\n",
      "Patient processed\n",
      "61\n",
      "Patient processed\n",
      "62\n",
      "Patient processed\n",
      "63\n",
      "Patient processed\n",
      "64\n",
      "Patient processed\n",
      "65\n",
      "Patient processed\n",
      "66\n",
      "Patient processed\n",
      "67\n",
      "Patient processed\n",
      "68\n",
      "Patient processed\n",
      "69\n",
      "Patient processed\n",
      "70\n",
      "Patient processed\n",
      "71\n",
      "Patient processed\n",
      "72\n",
      "Patient processed\n",
      "73\n",
      "Patient processed\n",
      "74\n",
      "Patient processed\n",
      "75\n",
      "Patient processed\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = Load_Data(r\"C:\\Users\\mhfar\\OneDrive\\Desktop\\20second_MNE_3CLASS\", include_rqa = False, wavelet_type = 'db4', wavelet_level = 9, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient processed\n",
      "0\n",
      "Patient processed\n",
      "1\n",
      "Patient processed\n",
      "2\n",
      "Patient processed\n",
      "3\n",
      "Patient processed\n",
      "4\n",
      "Patient processed\n",
      "5\n",
      "Patient processed\n",
      "6\n",
      "Patient processed\n",
      "7\n",
      "Patient processed\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = Load_Data(r\"C:\\Users\\mhfar\\OneDrive\\Desktop\\20second_MNE_3CLASS_TEST\", include_rqa = False, wavelet_type = 'db4', wavelet_level = 9, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data = Dataset.__getitem__(0)[0][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwavelet = 'sym5'\\nlevel = 9\\n\\nwavelet_features = []\\nfor channel in eeg_data:\\n    channel_features = extract_wavelet_features(channel, wavelet, level)\\n    wavelet_features.append(channel_features)\\n\\nwavelet_features = np.array(wavelet_features)\\nnp.shape(wavelet_features)\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "wavelet = 'sym5'\n",
    "level = 9\n",
    "\n",
    "wavelet_features = []\n",
    "for channel in eeg_data:\n",
    "    channel_features = extract_wavelet_features(channel, wavelet, level)\n",
    "    wavelet_features.append(channel_features)\n",
    "\n",
    "wavelet_features = np.array(wavelet_features)\n",
    "np.shape(wavelet_features)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "csp = CSP(n_components=21, reg=None, log=True, norm_trace=False)\n",
    "X_train_combined = np.hstack((X_train.reshape(X_train.shape[0], -1), csp.fit_transform(X_train, y_train)))\n",
    "X_test_combined = np.hstack((X_test.reshape(X_test.shape[0], -1), csp.fit_transform(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38724, 588)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=RandomForestClassifier(n_estimators=80,\n",
       "                                                     random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=RandomForestClassifier(n_estimators=80,\n",
       "                                                     random_state=42))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=80, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=80, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(n_estimators=80,\n",
       "                                                     random_state=42))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "rf_classifier = RandomForestClassifier(n_estimators=80, random_state=42)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=100)\n",
    "svm_classifier = SVC()\n",
    "ovr_classifier = OneVsRestClassifier(rf_classifier)\n",
    "ovr_classifier.fit(X_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70\n",
      "training time: 295.1083550453186\n"
     ]
    }
   ],
   "source": [
    "y_pred = ovr_classifier.predict(X_test_combined)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"training time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['randomforest.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ovr_classifier, \"randomforest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(FeatureGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x: Your feature vector (shape: [num_samples, input_dim])\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "input_dim = 819  # Dimension of your feature vector\n",
    "hidden_dim = 400  # Hidden layer dimension\n",
    "num_classes = 3  # Number of classes (e.g., 0, 1, 2)\n",
    "\n",
    "# Initialize the GNN model\n",
    "model = FeatureGNN(input_dim, hidden_dim, num_classes)\n",
    "edge_index = torch.randint(0, 819, (2, 200))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mhfar\\AppData\\Local\\Temp\\ipykernel_21256\\1728568494.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\mhfar\\AppData\\Local\\Temp\\ipykernel_21256\\1728568494.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "X_train_tensor = torch.tensor(X_train_combined, dtype=torch.float32)\n",
    "y_train_tensor = torch.nn.functional.one_hot(torch.tensor(y_train, dtype=torch.long).unsqueeze(1), 3).squeeze()\n",
    "y_train_tensor = torch.tensor(y_train_tensor, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_combined, dtype=torch.float32)\n",
    "y_test_tensor = torch.nn.functional.one_hot(torch.tensor(y_test, dtype=torch.long).unsqueeze(1), 3).squeeze()\n",
    "y_test_tensor = torch.tensor(y_test_tensor, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor, edge_index)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #print(f\"Epoch [{epoch+1}/100], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.argmax(model(X_test_tensor, edge_index), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy = accuracy_score(torch.argmax(y_test_tensor, axis = 1), predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
