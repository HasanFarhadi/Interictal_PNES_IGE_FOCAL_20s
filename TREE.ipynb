{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "import torch\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mne\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_packed_sequence\n",
    "import statistics\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Dataloader2.ipynb\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger('mne').setLevel(logging.WARNING)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import import_ipynb\n",
    "#from Model import net\n",
    "from Dataloader2 import EEGDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNE_Data = EEGDataset(root_dir=r\"C:\\Users\\admin\\Desktop\\TEST\")\n",
    "labels = MNE_Data.labels\n",
    "#MNE_Data = EEGDataset(root_dir=r\"D:\\TEST MNE\")\n",
    "test_path = r\"C:\\Users\\admin\\Desktop\\TEST\\amirifateme.fif\"\n",
    "test_class = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = MNE_Data.__getitem__(0)[0]\n",
    "eeg_data = patient[120]\n",
    "patient = np.random.randn(19400, 19, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 300  # Hz, replace with your actual sampling frequency\n",
    "\n",
    "# Function to calculate spectral entropy\n",
    "def spectral_entropy(signal, sf, method='welch', normalize=True):\n",
    "    # Compute the Power Spectral Density (PSD) using Welch's method\n",
    "    freqs, psd = welch(signal, sf)\n",
    "    \n",
    "    # Normalize the PSD to get a probability distribution, if required\n",
    "    if normalize:\n",
    "        psd_norm = psd / np.sum(psd)\n",
    "        return entropy(psd_norm)\n",
    "    else:\n",
    "        return entropy(psd)\n",
    "\n",
    "features = []\n",
    "for window in patient:\n",
    "    # Initialize an array to store the spectral entr\n",
    "    # opy for each channel\n",
    "    spectral_entropy_features = np.zeros((window.shape[0],))\n",
    "\n",
    "    # Calculate spectral entropy for each channel\n",
    "    for i in range(window.shape[0]):\n",
    "        spectral_entropy_features[i] = spectral_entropy(window[i, :], sf)\n",
    "\n",
    "    # Output the spectral entropy features\n",
    "    \n",
    "    features.append(spectral_entropy_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19400, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.random.randint(0, 4, size=(19400))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Assuming 'X' is your feature matrix with shape (194, n_features)\n",
    "# and 'y' is your label vector with the 4 classes encoded as 0, 1, 2, 3\n",
    "\n",
    "# Initialize the list of decision trees\n",
    "trees = []\n",
    "\n",
    "# Create and train a decision tree for each class\n",
    "for class_label in range(4):\n",
    "    # Create a binary label vector where the current class is 1 and all others are 0\n",
    "    y_binary = (y == class_label).astype(int)\n",
    "    \n",
    "    # Initialize the decision tree classifier\n",
    "    tree = DecisionTreeClassifier(random_state=42)\n",
    "    \n",
    "    # Train the classifier\n",
    "    tree.fit(features, y_binary)\n",
    "    \n",
    "    # Store the trained tree\n",
    "    trees.append(tree)\n",
    "\n",
    "# Function to predict using the sequence of decision trees\n",
    "def predict(features, trees):\n",
    "    predictions = []\n",
    "    \n",
    "    for sample in features:\n",
    "        for i, tree in enumerate(trees):\n",
    "            # Predict with the current tree\n",
    "            prediction = tree.predict([sample])\n",
    "            \n",
    "            # If the tree classifies the sample as the current class, break and assign that class\n",
    "            if prediction == 1:\n",
    "                predictions.append(i)\n",
    "                break\n",
    "        else:\n",
    "            # If none of the trees classify the sample as their class, assign a default class\n",
    "            predictions.append(0)  # You can choose how to handle this case\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example usage\n",
    "# X_test is your test feature matrix\n",
    "#predictions = predict(features, trees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree depth: 1\n",
      "0.25257731958762886\n",
      "tree depth: 2\n",
      "0.25304123711340204\n",
      "tree depth: 3\n",
      "0.25876288659793817\n",
      "tree depth: 4\n",
      "0.26123711340206185\n",
      "tree depth: 5\n",
      "0.26798969072164947\n",
      "tree depth: 6\n",
      "0.2754639175257732\n",
      "tree depth: 7\n",
      "0.28304123711340207\n",
      "tree depth: 8\n",
      "0.2910824742268041\n",
      "tree depth: 9\n",
      "0.30355670103092786\n",
      "tree depth: 10\n",
      "0.3154639175257732\n",
      "tree depth: 11\n",
      "0.3306185567010309\n",
      "tree depth: 12\n",
      "0.3504639175257732\n",
      "tree depth: 13\n",
      "0.3789175257731959\n",
      "tree depth: 14\n",
      "0.4060824742268041\n",
      "tree depth: 15\n",
      "0.4367525773195876\n",
      "tree depth: 16\n",
      "0.4692783505154639\n",
      "tree depth: 17\n",
      "0.5017525773195877\n",
      "tree depth: 18\n",
      "0.5364432989690722\n",
      "tree depth: 19\n",
      "0.5726288659793815\n",
      "tree depth: 20\n",
      "0.6094845360824742\n",
      "tree depth: 21\n",
      "0.6427835051546392\n",
      "tree depth: 22\n",
      "0.6752577319587629\n",
      "tree depth: 23\n",
      "0.7079896907216495\n",
      "tree depth: 24\n",
      "0.7405670103092783\n",
      "tree depth: 25\n",
      "0.7751546391752577\n",
      "tree depth: 26\n",
      "0.8060309278350516\n",
      "tree depth: 27\n",
      "0.8347422680412371\n",
      "tree depth: 28\n",
      "0.8618556701030928\n",
      "tree depth: 29\n",
      "0.8858762886597938\n",
      "tree depth: 30\n",
      "0.9065979381443299\n",
      "tree depth: 31\n",
      "0.9239175257731959\n",
      "tree depth: 32\n",
      "0.9406701030927835\n",
      "tree depth: 33\n",
      "0.9535567010309278\n",
      "tree depth: 34\n",
      "0.9638144329896907\n",
      "tree depth: 35\n",
      "0.9727835051546392\n",
      "tree depth: 36\n",
      "0.9803092783505155\n",
      "tree depth: 37\n",
      "0.9860309278350515\n",
      "tree depth: 38\n",
      "0.9903092783505154\n",
      "tree depth: 39\n",
      "0.994020618556701\n",
      "tree depth: 40\n",
      "0.9969072164948454\n"
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "    tree = DecisionTreeClassifier(max_depth=i+1)\n",
    "    tree.fit(features, y)\n",
    "    predictions = tree.predict(features)\n",
    "    print(f\"tree depth: {i+1}\")\n",
    "    print(np.mean(predictions == y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9695876288659794"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
